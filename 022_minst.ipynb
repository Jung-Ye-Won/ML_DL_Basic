{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홑일때 [0 2 3 0 2 3 0 2 3 0 2 3 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Kmeans를 tensorflow로 구현 => 행렬이해에 도움\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "val = [0,2,3]\n",
    "val = tf.tile(val,[5]) #타일링 5번반복하며 만들어짐\n",
    "print('홑일때', sess.run(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2차원일때 [[1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]\n",
      " [1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "val = [[1,1,1],[2,2,2],[3,3,3]] #3*3 -> 5*2 로타일링\n",
    "val = tf.tile(val,[5,2]) #행으로 5번, 곱 열로 2번 곱\n",
    "print('2차원일때', sess.run(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차원 확대 [[[ 1.  2.]]\n",
      "\n",
      " [[ 2.  1.]]\n",
      "\n",
      " [[-2. -1.]]]\n"
     ]
    }
   ],
   "source": [
    "input_vecs = [[1.,2.],[2.,1.],[-2.,-1.]]\n",
    "print('차원 확대', sess.run(tf.expand_dims(input_vecs,1))) #2차원 데이터 -> 3차원 데이터로 확장\n",
    "#1*3*2로 차원이 확대되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 4\n",
      "[[5.  3.5 1.6 0.6]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.9 3.2 5.7 2.3]]\n"
     ]
    }
   ],
   "source": [
    "#군집분석으로 target은 필요업당\n",
    "num_pts = len(iris.data) #데이터갯수\n",
    "num_feats = len(iris.data[0]) #변수갯수\n",
    "print(num_pts, num_feats)\n",
    "k = 3 #3개로 군집하겠다.\n",
    "generations = 10 #epochs를 의미한다. 세대\n",
    "\n",
    "#데이터 입력공간\n",
    "data_points = tf.Variable(iris.data) #variable에는 가중치가 들어간다. (데이터 양만큼 들어간다. 150*4)\n",
    "cluster_labels = tf.Variable(tf.zeros([num_pts], dtype=tf.int64)) #150개를 전부 0으로 생성 cluster label을 넣으려고 만듬\n",
    "\n",
    "rand_starts = np.array([iris.data[np.random.choice(len(iris.data))] for _ in range(k)]) #3번 돌아가면서, _횟수로만 k를 쓰겠다.\n",
    "#iris 데이터 중에서 하나씩을 세번 골라라 -> 중심값을 선정하기 위해서\n",
    "#[[각변수4개들어있음],[],[]] 형태를 갖게된다. 랜덤초이스를 3번해서 중심값을 선정하였다.\n",
    "#kmeans(k값, 중심값)\n",
    "print(rand_starts) #중심값을 랜덤으로 설정\n",
    "centroids = tf.Variable(rand_starts)\n",
    "\n",
    "#150개 만큼 복사해서 만듬 -> 3*4 -> 150*3*4 (reshape으로 명확하게 모양을 지정해준다.)\n",
    "#150*4의 기존데이터과 랜덤한 중심값3개와 각각 거리를 구해야 하기 때문에\n",
    "#150*4 를 통째로 복사해서 3개의 큰열을 만들면 위의 150*3*4의 중심값 3개와 거리값 계산이 가능하다.\n",
    "centroid_matrix = tf.reshape(tf.tile(centroids, [num_pts,1]), [num_pts, k, num_feats])\n",
    "point_matrix = tf.reshape(tf.tile(data_points, [1,k]), [num_pts, k, num_feats]) #data point에 대해서 반복하라.\n",
    "#150*4를 3번 복사해서 150*3*4를 만듬\n",
    "distance = tf.reduce_sum(tf.square(point_matrix - centroid_matrix), axis=2) #0,1,2 2=말단끼리 빼라, 빼서 제곱한것을 모두더함\n",
    "#거리값은 150*3으로 나온다.(마지막열(2) 빼고 나서 제곱하고 더하니까.)\n",
    "centroid_group = tf.argmin(distance, 1) #최소값\n",
    "#kmeans 중심값과의 거리를 재는것이 목적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 5, 5],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([[1,2,3,4],[5,6,7,8],[4,3,2,1]])\n",
    "sess.run(tf.unsorted_segment_sum(c, tf.constant([0,1,0]), num_segments=2))\n",
    "#unsorted_segment_sum - 데이터에대해 세그먼트 별로 합계를 줬는데 \n",
    "#그룹이 2개고 그 그룹을 0,1,0 번으로 주겠다. 같은그룹을 합쳐라\n",
    "#그룹변 합계를 낼 때 쓰는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n",
      " 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "세대 : 0, 전체 : 10\n",
      "그룹별 수 : [53, 62, 35]\n",
      "세대 : 1, 전체 : 10\n",
      "그룹별 수 : [50, 64, 36]\n",
      "세대 : 2, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 3, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 4, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 5, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 6, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 7, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 8, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "세대 : 9, 전체 : 10\n",
      "그룹별 수 : [50, 62, 38]\n",
      "[[5.006      3.428      1.462      0.246     ]\n",
      " [5.9016129  2.7483871  4.39354839 1.43387097]\n",
      " [6.85       3.07368421 5.74210526 2.07105263]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n",
      " 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n"
     ]
    }
   ],
   "source": [
    "def data_group_avg(group_ids, data):\n",
    "    #중심값을 재계산 하는 함수\n",
    "    sum_total = tf.unsorted_segment_sum(data, group_ids, 3) #요소별 합계가 된다.(그룹별로 3덩어리가 나온다.)\n",
    "    num_total = tf.unsorted_segment_sum(tf.ones_like(data), group_ids, 3) #ones_like - 1로 생성\n",
    "    avg_by_group = sum_total/num_total\n",
    "    #중심값이 된다.\n",
    "    return (avg_by_group)\n",
    "\n",
    "#그룹번호, 데이터\n",
    "print(sess.run(centroid_group))\n",
    "print(sess.run(data_points))\n",
    "means = data_group_avg(centroid_group, data_points) #중심값/실데이터값\n",
    "#중심값이 계산된 값으로 변경되었다. / 그룹번호도 변경되었다.\n",
    "update = tf.group(centroids.assign(means), cluster_labels.assign(centroid_group))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(generations):\n",
    "    print('세대 : {}, 전체 : {}'.format(i, generations))\n",
    "    _, centriod_group_count = sess.run([update, centroid_group])\n",
    "    group_count =[]\n",
    "    for ix in range(k):\n",
    "        group_count.append(np.sum(centriod_group_count==ix))\n",
    "    print('그룹별 수 : {}'.format(group_count))\n",
    "\n",
    "[centers, assignments] = sess.run([centroids, cluster_labels])\n",
    "print(centers, assignments)\n",
    "#정답은 50,50,50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0\n",
      "0 48 36\n",
      "Accuracy : 0.56\n"
     ]
    }
   ],
   "source": [
    "def most_common(my_list):\n",
    "    #센터값, 그룹할당 번호, set=중복되지 않는 key값 가장큰값\n",
    "    return (max(set(my_list), key = my_list.count))\n",
    "\n",
    "label0 = most_common(list(assignments[0:50])) #한그룹\n",
    "label1 = most_common(list(assignments[50:100]))\n",
    "label2 = most_common(list(assignments[100:150]))\n",
    "print(label0, label1, label2)\n",
    "\n",
    "group0_count = np.sum(assignments[0:50]==label0)\n",
    "group1_count = np.sum(assignments[50:100]==label1)\n",
    "group2_count = np.sum(assignments[100:150]==label2)\n",
    "print(group0_count, group1_count, group2_count)\n",
    "\n",
    "accuracy = (group0_count + group1_count + group2_count)/150\n",
    "print('Accuracy : {:.2}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import csv\n",
    "import random\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = 6\n",
    "batch_size = 50\n",
    "symmetry = ['rotate180', 'rotate90', 'rotate270', 'flip_v', 'flip_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(board):\n",
    "    symbols = ['o',' ','x']\n",
    "    board_plus1 = [int(x) + 1 for x in board]\n",
    "    print(' '+ symbols[board_plus1[0]]+' | '+symbols[board_plus1[1]]+' | '+symbols[board_plus1[2]])\n",
    "    print(' '+ symbols[board_plus1[3]]+' | '+symbols[board_plus1[4]]+' | '+symbols[board_plus1[5]])\n",
    "    print(' '+ symbols[board_plus1[6]]+' | '+symbols[board_plus1[7]]+' | '+symbols[board_plus1[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation하는 부분(증감)\n",
    "#0 1 2\n",
    "#3 4 5\n",
    "#6 7 8\n",
    "\n",
    "# data augmentation(증강 => 이미지) # 동일한 경우의 수 늘림\n",
    "def get_symmetry(board, response, transformation):\n",
    "    #보드 9개 response 1개\n",
    "    if transformation =='rotate180':\n",
    "        #180도를 돌려야 한다면\n",
    "        new_response = 8-response #새로운 위치는 8-response다.\n",
    "        return board[::-1], new_response\n",
    "    elif transformation == 'rotate90':\n",
    "        #시계방향으로 돌린다는 뜻\n",
    "        #6 3 0\n",
    "        #7 4 1\n",
    "        #8 5 2\n",
    "        new_response = [6,3,0,7,4,1,8,5,2].index(response)\n",
    "        tuple_board = list(zip(*[board[6:9], board[3:6], board[0:3]]))\n",
    "        return [value for item in tuple_board for value in item], new_response\n",
    "    elif transformation == 'rotate270':\n",
    "        new_response = [2,5,8,1,4,7,0,3,6].index(response)\n",
    "        tuple_board = list(zip(*[board[0:3], board[3:6], board[6:9]]))[::-1]\n",
    "        return [value for item in tuple_board for value in item], new_response\n",
    "    elif transformation == 'flip_v':\n",
    "        new_response = [6,7,8,3,4,5,0,1,2].index(response)\n",
    "        return board[6:9]+board[3:6]+board[0:3], new_response\n",
    "    elif transformation == 'flip_h':\n",
    "        new_response = [2,1,0,5,4,3,8,7,6].index(response)\n",
    "        new_board = board[::-1]\n",
    "        return new_board[6:9]+new_board[3:6]+new_board[0:3], new_response\n",
    "    else :\n",
    "        raise ValueError('해당하는 경우 없음')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "def get_moves_from_csv(csv_file):\n",
    "    moves = []\n",
    "    with open(csv_file, 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            moves.append(([int(x) for x in row[0:9]], int(row[9])))\n",
    "            #10개 들어와서 [[],1] : 2개\n",
    "    return moves\n",
    "\n",
    "def get_rand_move(moves, n=1, rand_transforms=2):\n",
    "    #데이터 증강 흐름\n",
    "    board, response = random.choice(moves)\n",
    "    #보드9개 response1개\n",
    "    possible_transforms = ['rotate90', 'rotate180', 'rotate270', 'flip_v', 'flip_h']\n",
    "    for i in range(rand_transforms):\n",
    "        random_transform = random.choice(possible_transforms)\n",
    "        board, response = get_symmetry(board, response, random_transform)\n",
    "    return board, response\n",
    "    \n",
    "moves = get_moves_from_csv('tic_moves.csv')\n",
    "train_length = 560\n",
    "train_set = []\n",
    "print(train_set)\n",
    "\n",
    "for t in range(train_length):\n",
    "    train_set.append(get_rand_move(moves))\n",
    "print(len(train_set))\n",
    "test_board = [-1,0,0,1,-1,-1,0,0,1]\n",
    "train_set = [x for x in train_set if x[0] != test_board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def init_weights(shape):\n",
    "    #가중치 초기화를 하기 위해서 하였다.\n",
    "    return (tf.Variable(tf.random_normal(shape)))\n",
    "def model(X, A1, A2, bias1, bias2):\n",
    "    # ?*9  9*81 -> 확대 \n",
    "    layer1 = tf.sigmoid(tf.add(tf.matmul(X,A1), bias1))\n",
    "    layer2 = tf.add(tf.matmul(layer1,A2), bias2)\n",
    "    return layer2\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 9])\n",
    "Y = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "A1 = init_weights([9,81])\n",
    "bias1 = init_weights([81])\n",
    "A2 = init_weights([81,9])\n",
    "bias2 = init_weights([9])\n",
    "model_output = model(X, A1, A2, bias1, bias2) #예측한놈 - 9개의 확률로 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복횟수 : 0Loss8.49772\n",
      "반복횟수 : 500Loss1.8740561\n",
      "반복횟수 : 1000Loss1.6210823\n",
      "반복횟수 : 1500Loss1.3739865\n",
      "반복횟수 : 2000Loss1.2092212\n",
      "반복횟수 : 2500Loss1.2993684\n",
      "반복횟수 : 3000Loss1.2426858\n",
      "반복횟수 : 3500Loss1.3082433\n",
      "반복횟수 : 4000Loss0.99111396\n",
      "반복횟수 : 4500Loss1.1372944\n",
      "반복횟수 : 5000Loss1.1760782\n",
      "반복횟수 : 5500Loss0.9567798\n",
      "반복횟수 : 6000Loss0.9416491\n",
      "반복횟수 : 6500Loss0.75842667\n",
      "반복횟수 : 7000Loss0.7606417\n",
      "반복횟수 : 7500Loss0.90712076\n",
      "반복횟수 : 8000Loss0.9168369\n",
      "반복횟수 : 8500Loss0.78217286\n",
      "반복횟수 : 9000Loss0.8903214\n",
      "반복횟수 : 9500Loss0.94074446\n",
      "반복횟수 : 10000Loss0.72612494\n",
      "반복횟수 : 10500Loss0.67806005\n",
      "반복횟수 : 11000Loss0.7937207\n",
      "반복횟수 : 11500Loss0.6459642\n",
      "반복횟수 : 12000Loss0.7049648\n",
      "반복횟수 : 12500Loss0.84382117\n",
      "반복횟수 : 13000Loss0.7082331\n",
      "반복횟수 : 13500Loss0.55357283\n",
      "반복횟수 : 14000Loss0.66831857\n",
      "반복횟수 : 14500Loss0.6063504\n",
      "반복횟수 : 15000Loss0.7982518\n",
      "반복횟수 : 15500Loss0.6571955\n",
      "반복횟수 : 16000Loss0.6393363\n",
      "반복횟수 : 16500Loss0.5158881\n",
      "반복횟수 : 17000Loss0.5775148\n",
      "반복횟수 : 17500Loss0.6282716\n",
      "반복횟수 : 18000Loss0.53511655\n",
      "반복횟수 : 18500Loss0.62965584\n",
      "반복횟수 : 19000Loss0.5660018\n",
      "반복횟수 : 19500Loss0.49791327\n",
      "반복횟수 : 20000Loss0.5000709\n",
      "반복횟수 : 20500Loss0.49765807\n",
      "반복횟수 : 21000Loss0.5633183\n",
      "반복횟수 : 21500Loss0.49134824\n",
      "반복횟수 : 22000Loss0.5876711\n",
      "반복횟수 : 22500Loss0.5259775\n",
      "반복횟수 : 23000Loss0.6303936\n",
      "반복횟수 : 23500Loss0.49778137\n",
      "반복횟수 : 24000Loss0.52206904\n",
      "반복횟수 : 24500Loss0.5266051\n",
      "반복횟수 : 25000Loss0.55021197\n",
      "반복횟수 : 25500Loss0.49521056\n",
      "반복횟수 : 26000Loss0.6758565\n",
      "반복횟수 : 26500Loss0.44547355\n",
      "반복횟수 : 27000Loss0.46772873\n",
      "반복횟수 : 27500Loss0.3595998\n",
      "반복횟수 : 28000Loss0.48533764\n",
      "반복횟수 : 28500Loss0.49098024\n",
      "반복횟수 : 29000Loss0.41809118\n",
      "반복횟수 : 29500Loss0.42675668\n",
      "반복횟수 : 30000Loss0.43731672\n",
      "반복횟수 : 30500Loss0.56880915\n",
      "반복횟수 : 31000Loss0.49439466\n",
      "반복횟수 : 31500Loss0.32179475\n",
      "반복횟수 : 32000Loss0.4988653\n",
      "반복횟수 : 32500Loss0.34952235\n",
      "반복횟수 : 33000Loss0.40438908\n",
      "반복횟수 : 33500Loss0.39651173\n",
      "반복횟수 : 34000Loss0.4154535\n",
      "반복횟수 : 34500Loss0.5320366\n",
      "반복횟수 : 35000Loss0.4317853\n",
      "반복횟수 : 35500Loss0.3901805\n",
      "반복횟수 : 36000Loss0.38398045\n",
      "반복횟수 : 36500Loss0.480924\n",
      "반복횟수 : 37000Loss0.44391498\n",
      "반복횟수 : 37500Loss0.47640648\n",
      "반복횟수 : 38000Loss0.48005828\n",
      "반복횟수 : 38500Loss0.41259003\n",
      "반복횟수 : 39000Loss0.41376466\n",
      "반복횟수 : 39500Loss0.37884602\n",
      "반복횟수 : 40000Loss0.32724553\n",
      "반복횟수 : 40500Loss0.40797222\n",
      "반복횟수 : 41000Loss0.38044074\n",
      "반복횟수 : 41500Loss0.36610577\n",
      "반복횟수 : 42000Loss0.4880129\n",
      "반복횟수 : 42500Loss0.49967453\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#확률로 다중분류기로 9개의 말자리중에 어떤자리가 될지를 확률값으로 말해준다.\n",
    "#분류시의 cost function\n",
    "#지도학습 (라벨은 결정이 되어있다.)\n",
    "#cross_entropy - 두 데이터의 확률관계를 이용해서 복잡도를 표현한다. (log값 이용)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = model_output, labels=Y))\n",
    "#learning rate를 주고 0.025 미니마이즈 중\n",
    "train_step = tf.train.GradientDescentOptimizer(0.025).minimize(loss)\n",
    "prediction = tf.argmax(model_output, 1) #확률이 가장큰놈 - 말위치가됨\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "loss_vec = []\n",
    "for i in range(50000):\n",
    "    #10000번 돌면서 학습할때 target을 1\n",
    "    rand_indices = np.random.choice(range(len(train_set)), batch_size, replace=False)\n",
    "    #훈련받을 데이터가 stochastic(확률적으로)하게 mini-batch(전체중에 50개만 뽑아서)로 선택된다. -> 지역해 없고 속도 빠르다.\n",
    "    batch_data = [train_set[i] for i in rand_indices]\n",
    "    #print(len(batch_data))\n",
    "    x_input = [x[0] for x in batch_data]\n",
    "    #print(x_input) #50*9\n",
    "    y_target = np.array([y[1] for y in batch_data])\n",
    "    #print(y_target) #50*1\n",
    "    sess.run(train_step, feed_dict={X:x_input, Y:y_target})\n",
    "    temp_loss = sess.run(loss, feed_dict={X:x_input, Y:y_target})\n",
    "    loss_vec.append(temp_loss)\n",
    "    if i%500 ==0:\n",
    "        #500번마다 메세지를 출력\n",
    "        print('반복횟수 : '+str(i)+'Loss'+str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_vec, 'k-', label='loss')\n",
    "plt.title('Loss(MSE)')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "test_boards = [test_board]\n",
    "feed_dict = {X:test_boards}\n",
    "logits = sess.run(model_output, feed_dict = feed_dict)\n",
    "predictions = sess.run(prediction, feed_dict = feed_dict)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(board):\n",
    "    #게임의 승패를 결정하는것 - 종료조건\n",
    "    #컴퓨터에 인공지능을 달아주는 것\n",
    "    wins = [[0,1,2],[3,4,5],[6,7,8],[1,4,7],[2,5,8],[0,4,8],[2,4,6]] #이기는 인덱스의 경우의수\n",
    "    for i in range(len(wins)):\n",
    "        if board[wins[i][0]]==board[wins[i][1]]==board[wins[i][2]]==1.:\n",
    "            return (1)\n",
    "        elif board[wins[i][0]]==board[wins[i][1]]==board[wins[i][2]]==-1.:\n",
    "            return (-1)\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#유저인 경우 = 1, 컴퓨터인 경우 = -1\n",
    "game_tracker = [0.,0.,0.,0.,0.,0.,0.,0.,0.] #말을표시하는것 9개\n",
    "win_logical = False\n",
    "num_moves = 0\n",
    "while not win_logical:\n",
    "    player_index = input('이동하고 싶은 인덱스를 입력하시오(0-8) : ')\n",
    "    num_moves += 1 #이동횟수를 세기 위해서\n",
    "    game_tracker[int(player_index)]=1.\n",
    "    [potential_moves] = sess.run(model_output, feed_dict={X:[game_tracker]}) #확률이 나온다.(모델에서 놓을자리를 예측한다.)\n",
    "    allowed_moves = [ix for ix, x in enumerate(game_tracker) if x ==0.0] \n",
    "    #말위치를 결정 :컴퓨터카 놓는말\n",
    "    model_move =  np.argmax([x if ix in allowed_moves else -999.0 for ix,x in enumerate(potential_moves)])\n",
    "    game_tracker[int(model_move)] = -1\n",
    "    print('모델이 이동하였습니다.')\n",
    "    print_board(game_tracker)\n",
    "    if check(game_tracker) ==1 or num_moves >=20:\n",
    "        #모델 종료 조건을 본다.\n",
    "        print('게임종료! 승리하였습니다.')\n",
    "        win_logical = True\n",
    "    elif check(game_tracker) ==-1:\n",
    "        print('게임종료! 게임에 지셨습니다.')\n",
    "        win_logical = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True) #이미지 로딩\n",
    "#0000100000 -> 4이다. (원핫인코딩 되었기 때문에)\n",
    "print(mnist.train.images.shape) #55000장이 들어옴 숫자그림\n",
    "\n",
    "first_image = mnist.train.images[0]\n",
    "print(mnist.test.images.shape) #10000장의 test 그림\n",
    "first_image = np.array(first_image, dtype='float') #이미지를 배열로 만들었다.\n",
    "pixels = first_image.reshape((28,28)) #이미지로 변경되었다. (사이즈 전환)\n",
    "plt.imshow(pixels, cmap='gray') #흑백이미지로 gray해서 보았음\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "0.4889\n",
      "0.4245\n",
      "0.403\n",
      "0.4504\n",
      "0.6295\n",
      "0.6397\n",
      "0.7022\n",
      "0.6643\n",
      "0.7101\n",
      "0.6526\n",
      "0.7162\n",
      "0.7366\n",
      "0.7457\n",
      "0.7281\n",
      "0.8224\n",
      "0.8422\n",
      "0.8246\n",
      "0.8317\n",
      "0.8268\n",
      "0.8463\n",
      "0.8595\n",
      "0.8395\n",
      "0.8594\n",
      "0.8607\n",
      "0.8659\n",
      "0.8638\n",
      "0.8579\n",
      "0.8446\n",
      "0.8471\n",
      "0.8682\n",
      "0.8713\n",
      "0.8721\n",
      "0.8579\n",
      "0.8713\n",
      "0.8604\n",
      "0.8731\n",
      "0.8687\n",
      "0.8688\n",
      "0.8724\n",
      "0.8773\n",
      "0.8773\n",
      "0.8698\n",
      "0.8794\n",
      "0.8818\n",
      "0.8779\n",
      "0.8821\n",
      "0.8769\n",
      "0.8731\n",
      "0.8812\n",
      "0.8754\n",
      "0.8766\n",
      "0.8842\n",
      "0.8833\n",
      "0.8801\n",
      "0.8803\n",
      "0.8793\n",
      "0.8815\n",
      "0.8864\n",
      "0.8728\n",
      "0.8596\n",
      "0.8762\n",
      "0.8796\n",
      "0.8794\n",
      "0.8807\n",
      "0.878\n",
      "0.8782\n",
      "0.8873\n",
      "0.8807\n",
      "0.8831\n",
      "0.8802\n",
      "0.8838\n",
      "0.8842\n",
      "0.8843\n",
      "0.8828\n",
      "0.8857\n",
      "0.8737\n",
      "0.8869\n",
      "0.8801\n",
      "0.8834\n",
      "0.8912\n",
      "0.887\n",
      "0.8733\n",
      "0.8745\n",
      "0.8881\n",
      "0.8867\n",
      "0.8757\n",
      "0.8899\n",
      "0.8924\n",
      "0.8854\n",
      "0.8924\n",
      "0.8839\n",
      "0.8932\n",
      "0.8928\n",
      "0.8848\n",
      "0.8885\n",
      "0.8901\n",
      "0.8936\n",
      "0.8921\n",
      "0.8932\n",
      "0.887\n",
      "0.8936\n",
      "0.8952\n",
      "0.8947\n",
      "0.8933\n",
      "0.8893\n",
      "0.8926\n",
      "0.8966\n",
      "0.8992\n",
      "0.8979\n",
      "0.8938\n",
      "0.8971\n",
      "0.8906\n",
      "0.8941\n",
      "0.894\n",
      "0.8937\n",
      "0.8999\n",
      "0.9004\n",
      "0.8984\n",
      "0.9005\n",
      "0.8907\n",
      "0.8965\n",
      "0.8958\n",
      "0.8927\n",
      "0.9007\n",
      "0.8986\n",
      "0.9008\n",
      "0.9009\n",
      "0.9014\n",
      "0.8996\n",
      "0.8921\n",
      "0.8976\n",
      "0.9008\n",
      "0.9007\n",
      "0.9025\n",
      "0.9025\n",
      "0.9048\n",
      "0.9\n",
      "0.8993\n",
      "0.8964\n",
      "0.8952\n",
      "0.8937\n",
      "0.8954\n",
      "0.9017\n",
      "0.8999\n",
      "0.9043\n",
      "0.9004\n",
      "0.8989\n",
      "0.9025\n",
      "0.9007\n",
      "0.9014\n",
      "0.9054\n",
      "0.9038\n",
      "0.9027\n",
      "0.8992\n",
      "0.8977\n",
      "0.9028\n",
      "0.9044\n",
      "0.9032\n",
      "0.9042\n",
      "0.9015\n",
      "0.8987\n",
      "0.9009\n",
      "0.9022\n",
      "0.903\n",
      "0.9023\n",
      "0.9052\n",
      "0.9003\n",
      "0.902\n",
      "0.9055\n",
      "0.9071\n",
      "0.8988\n",
      "0.9014\n",
      "0.9052\n",
      "0.9001\n",
      "0.8949\n",
      "0.9008\n",
      "0.9066\n",
      "0.907\n",
      "0.9023\n",
      "0.9057\n",
      "0.9052\n",
      "0.9062\n",
      "0.9022\n",
      "0.9067\n",
      "0.9081\n",
      "0.9019\n",
      "0.9081\n",
      "0.9078\n",
      "0.901\n",
      "0.9052\n",
      "0.9019\n",
      "0.9073\n",
      "0.9063\n",
      "0.9034\n",
      "0.901\n",
      "0.9036\n",
      "0.9043\n",
      "0.9051\n",
      "0.9025\n",
      "0.8969\n",
      "0.901\n",
      "0.9032\n",
      "0.9055\n",
      "0.9057\n",
      "0.9053\n",
      "0.9057\n",
      "0.9061\n",
      "0.9065\n",
      "0.9022\n",
      "0.9076\n",
      "0.9031\n",
      "0.897\n",
      "0.9023\n",
      "0.8984\n",
      "0.9026\n",
      "0.9043\n",
      "0.906\n",
      "0.906\n",
      "0.9033\n",
      "0.9061\n",
      "0.9041\n",
      "0.9024\n",
      "0.9044\n",
      "0.8983\n",
      "0.9058\n",
      "0.906\n",
      "0.9041\n",
      "0.9086\n",
      "0.9058\n",
      "0.9078\n",
      "0.9024\n",
      "0.902\n",
      "0.9036\n",
      "0.8999\n",
      "0.9051\n",
      "0.9045\n",
      "0.9048\n",
      "0.905\n",
      "0.904\n",
      "0.9021\n",
      "0.9019\n",
      "0.9021\n",
      "0.9054\n",
      "0.9073\n",
      "0.9017\n",
      "0.9046\n",
      "0.9077\n",
      "0.907\n",
      "0.9064\n",
      "0.906\n",
      "0.9057\n",
      "0.9049\n",
      "0.9061\n",
      "0.904\n",
      "0.9032\n",
      "0.9077\n",
      "0.9061\n",
      "0.9087\n",
      "0.9024\n",
      "0.9055\n",
      "0.9072\n",
      "0.9056\n",
      "0.9061\n",
      "0.9038\n",
      "0.9054\n",
      "0.9032\n",
      "0.9029\n",
      "0.9079\n",
      "0.9083\n",
      "0.9092\n",
      "0.9094\n",
      "0.9087\n",
      "0.9085\n",
      "0.9069\n",
      "0.9062\n",
      "0.9032\n",
      "0.9072\n",
      "0.9076\n",
      "0.9076\n",
      "0.907\n",
      "0.9046\n",
      "0.9063\n",
      "0.9077\n",
      "0.9096\n",
      "0.9084\n",
      "0.9073\n",
      "0.9067\n",
      "0.9083\n",
      "0.9056\n",
      "0.9062\n",
      "0.9061\n",
      "0.9085\n",
      "0.9105\n",
      "0.9098\n",
      "0.907\n",
      "0.9001\n",
      "0.9081\n",
      "0.9083\n",
      "0.9079\n",
      "0.9071\n",
      "0.9068\n",
      "0.9055\n",
      "0.9069\n",
      "0.9056\n",
      "0.9062\n",
      "0.9074\n",
      "0.9068\n",
      "0.9073\n",
      "0.9083\n",
      "0.905\n",
      "0.9112\n",
      "0.9086\n",
      "0.9079\n",
      "0.9105\n",
      "0.9118\n",
      "0.9096\n",
      "0.9095\n",
      "0.9076\n",
      "0.9103\n",
      "0.911\n",
      "0.9097\n",
      "0.9129\n",
      "0.9112\n",
      "0.9113\n",
      "0.9109\n",
      "0.91\n",
      "0.9119\n",
      "0.9117\n",
      "0.9129\n",
      "0.9102\n",
      "0.9067\n",
      "0.91\n",
      "0.9112\n",
      "0.9046\n",
      "0.9056\n",
      "0.9065\n",
      "0.9101\n",
      "0.9097\n",
      "0.9073\n",
      "0.9076\n",
      "0.913\n",
      "0.9109\n",
      "0.9066\n",
      "0.9091\n",
      "0.9092\n",
      "0.908\n",
      "0.9106\n",
      "0.9047\n",
      "0.9062\n",
      "0.9081\n",
      "0.9086\n",
      "0.9038\n",
      "0.9084\n",
      "0.9116\n",
      "0.9097\n",
      "0.9095\n",
      "0.9093\n",
      "0.9019\n",
      "0.9091\n",
      "0.9076\n",
      "0.9126\n",
      "0.9121\n",
      "0.908\n",
      "0.9095\n",
      "0.9079\n",
      "0.9094\n",
      "0.9075\n",
      "0.9111\n",
      "0.9089\n",
      "0.9133\n",
      "0.9066\n",
      "0.914\n",
      "0.9138\n",
      "0.9077\n",
      "0.9093\n",
      "0.9023\n",
      "0.9117\n",
      "0.9102\n",
      "0.912\n",
      "0.9032\n",
      "0.9072\n",
      "0.9073\n",
      "0.9113\n",
      "0.9091\n",
      "0.9083\n",
      "0.9103\n",
      "0.914\n",
      "0.9126\n",
      "0.9105\n",
      "0.9099\n",
      "0.9135\n",
      "0.9149\n",
      "0.9096\n",
      "0.9115\n",
      "0.9104\n",
      "0.9122\n",
      "0.9115\n",
      "0.9132\n",
      "0.9099\n",
      "0.9086\n",
      "0.9124\n",
      "0.912\n",
      "0.9101\n",
      "0.9105\n",
      "0.9107\n",
      "0.9117\n",
      "0.9117\n",
      "0.9116\n",
      "0.9125\n",
      "0.9107\n",
      "0.9115\n",
      "0.9079\n",
      "0.9081\n",
      "0.9068\n",
      "0.9106\n",
      "0.9134\n",
      "0.9125\n",
      "0.9155\n",
      "0.917\n",
      "0.9075\n",
      "0.9139\n",
      "0.9152\n",
      "0.9124\n",
      "0.9148\n",
      "0.9147\n",
      "0.9074\n",
      "0.914\n",
      "0.9111\n",
      "0.9073\n",
      "0.9102\n",
      "0.9163\n",
      "0.9122\n",
      "0.9145\n",
      "0.9126\n",
      "0.9141\n",
      "0.9139\n",
      "0.911\n",
      "0.9093\n",
      "0.9108\n",
      "0.9121\n",
      "0.9117\n",
      "0.9135\n",
      "0.9163\n",
      "0.9163\n",
      "0.9103\n",
      "0.9139\n",
      "0.9126\n",
      "0.9104\n",
      "0.9108\n",
      "0.9155\n",
      "0.9142\n",
      "0.915\n",
      "0.9146\n",
      "0.9149\n",
      "0.9111\n",
      "0.9151\n",
      "0.9113\n",
      "0.9129\n",
      "0.9131\n",
      "0.9116\n",
      "0.9172\n",
      "0.913\n",
      "0.9144\n",
      "0.9166\n",
      "0.9147\n",
      "0.9171\n",
      "0.9152\n",
      "0.9149\n",
      "0.9164\n",
      "0.9114\n",
      "0.915\n",
      "0.9158\n",
      "0.9172\n",
      "0.9173\n",
      "0.9131\n",
      "0.9153\n",
      "0.9163\n",
      "0.9145\n",
      "0.9097\n",
      "0.9146\n",
      "0.9162\n",
      "0.9164\n",
      "0.9158\n",
      "0.9145\n",
      "0.917\n",
      "0.9152\n",
      "0.9161\n",
      "0.9114\n",
      "0.9148\n",
      "0.9145\n",
      "0.9147\n",
      "0.9144\n",
      "0.9161\n",
      "0.9167\n",
      "0.9144\n",
      "0.9112\n",
      "0.9167\n",
      "0.9128\n",
      "0.9137\n",
      "0.9149\n",
      "0.9156\n",
      "0.9155\n",
      "0.9113\n",
      "0.9149\n",
      "0.9108\n",
      "0.9148\n",
      "0.9133\n",
      "0.9112\n",
      "0.9136\n",
      "0.9135\n",
      "0.9103\n",
      "0.9079\n",
      "0.9133\n",
      "0.9116\n",
      "0.9144\n",
      "0.9139\n",
      "0.916\n",
      "0.913\n",
      "0.9139\n",
      "0.9133\n",
      "0.9157\n",
      "0.9163\n",
      "0.909\n",
      "0.913\n",
      "0.915\n",
      "0.9143\n",
      "0.9117\n",
      "0.9173\n",
      "0.9139\n",
      "0.9156\n",
      "0.9137\n",
      "0.9151\n",
      "0.9154\n",
      "0.9156\n",
      "0.9155\n",
      "0.9169\n",
      "0.9123\n",
      "0.9167\n",
      "0.9137\n",
      "0.9163\n",
      "0.911\n",
      "0.9099\n",
      "0.9152\n",
      "0.9154\n",
      "0.9136\n",
      "0.9152\n",
      "0.9083\n",
      "0.9155\n",
      "0.9135\n",
      "0.9152\n",
      "0.9144\n",
      "0.917\n",
      "0.9184\n",
      "0.9133\n",
      "0.9185\n",
      "0.9146\n",
      "0.9146\n",
      "0.9149\n",
      "0.9177\n",
      "0.912\n",
      "0.9127\n",
      "0.9155\n",
      "0.9154\n",
      "0.9139\n",
      "0.9155\n",
      "0.9165\n",
      "0.9176\n",
      "0.913\n",
      "0.9176\n",
      "0.9158\n",
      "0.9175\n",
      "0.917\n",
      "0.9159\n",
      "0.9175\n",
      "0.9185\n",
      "0.9158\n",
      "0.9162\n",
      "0.9138\n",
      "0.9117\n",
      "0.9056\n",
      "0.918\n",
      "0.9192\n",
      "0.9128\n",
      "0.9145\n",
      "0.9176\n",
      "0.9143\n",
      "0.9148\n",
      "0.9111\n",
      "0.9151\n",
      "0.9198\n",
      "0.9153\n",
      "0.9137\n",
      "0.9157\n",
      "0.9151\n",
      "0.9159\n",
      "0.9182\n",
      "0.9164\n",
      "0.9122\n",
      "0.9117\n",
      "0.9122\n",
      "0.9154\n",
      "0.9162\n",
      "0.912\n",
      "0.9119\n",
      "0.9135\n",
      "0.9154\n",
      "0.9116\n",
      "0.9153\n",
      "0.915\n",
      "0.916\n",
      "0.9184\n",
      "0.918\n",
      "0.9154\n",
      "0.9133\n",
      "0.9155\n",
      "0.9167\n",
      "0.9181\n",
      "0.9181\n",
      "0.9174\n",
      "0.9098\n",
      "0.9162\n",
      "0.914\n",
      "0.9158\n",
      "0.917\n",
      "0.9186\n",
      "0.9164\n",
      "0.9143\n",
      "0.9161\n",
      "0.9151\n",
      "0.9163\n",
      "0.9122\n",
      "0.9134\n",
      "0.9135\n",
      "0.9125\n",
      "0.9147\n",
      "0.9179\n",
      "0.9184\n",
      "0.9132\n",
      "0.9188\n",
      "0.9121\n",
      "0.9111\n",
      "0.9122\n",
      "0.9139\n",
      "0.9154\n",
      "0.9093\n",
      "0.9143\n",
      "0.9178\n",
      "0.9141\n",
      "0.9157\n",
      "0.9159\n",
      "0.9153\n",
      "0.9164\n",
      "0.9149\n",
      "0.9131\n",
      "0.9142\n",
      "0.9177\n",
      "0.9172\n",
      "0.9171\n",
      "0.9177\n",
      "0.917\n",
      "0.9159\n",
      "0.9193\n",
      "0.9193\n",
      "0.917\n",
      "0.9096\n",
      "0.9143\n",
      "0.9131\n",
      "0.9164\n",
      "0.915\n",
      "0.9145\n",
      "0.9169\n",
      "0.9154\n",
      "0.9168\n",
      "0.9148\n",
      "0.9133\n",
      "0.9119\n",
      "0.9152\n",
      "0.9197\n",
      "0.9157\n",
      "0.9172\n",
      "0.9177\n",
      "0.9142\n",
      "0.9168\n",
      "0.917\n",
      "0.9133\n",
      "0.9189\n",
      "0.9182\n",
      "0.9169\n",
      "0.9162\n",
      "0.9184\n",
      "0.9184\n",
      "0.918\n",
      "0.9181\n",
      "0.9194\n",
      "0.9177\n",
      "0.9178\n",
      "0.9192\n",
      "0.9121\n",
      "0.9138\n",
      "0.9153\n",
      "0.9154\n",
      "0.9156\n",
      "0.9104\n",
      "0.9131\n",
      "0.9147\n",
      "0.9171\n",
      "0.9107\n",
      "0.9147\n",
      "0.9123\n",
      "0.9161\n",
      "0.9163\n",
      "0.9175\n",
      "0.9137\n",
      "0.9161\n",
      "0.9171\n",
      "0.9168\n",
      "0.916\n",
      "0.9171\n",
      "0.9148\n",
      "0.9163\n",
      "0.9145\n",
      "0.9131\n",
      "0.9151\n",
      "0.9172\n",
      "0.9176\n",
      "0.9164\n",
      "0.9168\n",
      "0.9158\n",
      "0.9168\n",
      "0.9178\n",
      "0.9147\n",
      "0.9177\n",
      "0.9186\n",
      "0.9173\n",
      "0.9135\n",
      "0.9131\n",
      "0.9151\n",
      "0.9173\n",
      "0.9176\n",
      "0.9134\n",
      "0.9144\n",
      "0.9156\n",
      "0.917\n",
      "0.9162\n",
      "0.9133\n",
      "0.9148\n",
      "0.9148\n",
      "0.9105\n",
      "0.9154\n",
      "0.9138\n",
      "0.9152\n",
      "0.9122\n",
      "0.9122\n",
      "0.9161\n",
      "0.9169\n",
      "0.9181\n",
      "0.9183\n",
      "0.9121\n",
      "0.9135\n",
      "0.9179\n",
      "0.9164\n",
      "0.918\n",
      "0.9186\n",
      "0.9169\n",
      "0.9177\n",
      "0.9187\n",
      "0.9172\n",
      "0.9173\n",
      "0.9176\n",
      "0.9154\n",
      "0.9175\n",
      "0.9176\n",
      "0.9158\n",
      "0.917\n",
      "0.9168\n",
      "0.9186\n",
      "0.9157\n",
      "0.911\n",
      "0.9155\n",
      "0.9127\n",
      "0.9149\n",
      "0.9144\n",
      "0.9172\n",
      "0.9175\n",
      "0.9174\n",
      "0.9149\n",
      "0.9144\n",
      "0.9167\n",
      "0.9169\n",
      "0.9191\n",
      "0.9182\n",
      "0.9182\n",
      "0.9159\n",
      "0.9126\n",
      "0.909\n",
      "0.9091\n",
      "0.9134\n",
      "0.9191\n",
      "0.919\n",
      "0.9142\n",
      "0.9197\n",
      "0.9171\n",
      "0.9174\n",
      "0.916\n",
      "0.914\n",
      "0.9158\n",
      "0.9138\n",
      "0.9146\n",
      "0.9104\n",
      "0.9162\n",
      "0.9154\n",
      "0.9193\n",
      "0.9165\n",
      "0.9158\n",
      "0.9192\n",
      "0.9185\n",
      "0.9165\n",
      "0.9136\n",
      "0.9129\n",
      "0.9155\n",
      "0.9153\n",
      "0.9173\n",
      "0.916\n",
      "0.9124\n",
      "0.9167\n",
      "0.9155\n",
      "0.9131\n",
      "0.9175\n",
      "0.9165\n",
      "0.9176\n",
      "0.9152\n",
      "0.9177\n",
      "0.9161\n",
      "0.9158\n",
      "0.9181\n",
      "0.9167\n",
      "0.9195\n",
      "0.9194\n",
      "0.9193\n",
      "0.9165\n",
      "0.9179\n",
      "0.9172\n",
      "0.9134\n",
      "0.916\n",
      "0.9181\n",
      "0.913\n",
      "0.9158\n",
      "0.9175\n",
      "0.9179\n",
      "0.9181\n",
      "0.9149\n",
      "0.9168\n",
      "0.9169\n",
      "0.9164\n",
      "0.9177\n",
      "0.914\n",
      "0.9165\n",
      "0.9176\n",
      "0.9133\n",
      "0.9152\n",
      "0.9142\n",
      "0.9172\n",
      "0.9166\n",
      "0.919\n",
      "0.9156\n",
      "0.9191\n",
      "0.9174\n",
      "0.917\n",
      "0.9172\n",
      "0.9169\n",
      "0.9153\n",
      "0.9154\n",
      "0.9157\n",
      "0.9162\n",
      "0.9155\n",
      "0.9163\n",
      "0.9165\n",
      "0.9166\n",
      "0.9168\n",
      "0.9143\n",
      "0.9138\n",
      "0.9161\n",
      "0.9173\n",
      "0.9156\n",
      "0.917\n",
      "0.9167\n",
      "0.9177\n",
      "0.9203\n",
      "0.9202\n",
      "0.9198\n",
      "0.9196\n",
      "0.9112\n",
      "0.9102\n",
      "0.917\n",
      "0.918\n",
      "0.9155\n",
      "0.9216\n",
      "0.9157\n",
      "0.9145\n",
      "0.9211\n",
      "0.9143\n",
      "0.915\n",
      "0.9113\n",
      "0.9172\n",
      "0.9151\n",
      "0.9187\n",
      "0.9171\n",
      "0.9198\n",
      "0.92\n",
      "0.9166\n",
      "0.9169\n",
      "0.9169\n",
      "0.921\n",
      "0.9187\n",
      "0.919\n",
      "0.9166\n",
      "0.9165\n",
      "0.9202\n",
      "0.9205\n",
      "0.9206\n",
      "0.9182\n",
      "0.9202\n",
      "0.9201\n",
      "0.9155\n",
      "0.9119\n",
      "0.918\n",
      "0.9168\n",
      "0.9174\n",
      "0.9179\n",
      "0.9168\n",
      "0.9175\n",
      "0.917\n",
      "0.9135\n",
      "0.9157\n",
      "0.9172\n",
      "0.9151\n",
      "0.9187\n",
      "0.916\n",
      "0.92\n",
      "0.9194\n",
      "0.9194\n",
      "0.9177\n",
      "0.9197\n",
      "0.9195\n",
      "0.916\n",
      "0.9181\n",
      "0.9167\n",
      "0.9174\n",
      "0.919\n",
      "0.915\n",
      "0.9119\n",
      "0.9148\n",
      "0.9171\n",
      "0.9187\n",
      "0.9171\n",
      "0.9176\n",
      "0.908\n",
      "0.9159\n",
      "0.9145\n",
      "0.9162\n",
      "0.914\n",
      "0.9195\n",
      "0.9197\n",
      "0.9175\n",
      "0.9202\n",
      "0.9181\n",
      "0.9139\n",
      "0.9194\n",
      "0.9184\n",
      "0.9166\n",
      "0.9169\n",
      "0.9142\n",
      "0.9086\n",
      "0.9169\n",
      "0.9143\n",
      "0.9135\n",
      "0.9152\n",
      "0.916\n",
      "0.917\n",
      "0.916\n",
      "0.9178\n",
      "0.9151\n",
      "0.9135\n",
      "0.9145\n",
      "0.9175\n",
      "0.9182\n",
      "0.9194\n",
      "0.9183\n",
      "0.9124\n",
      "0.9135\n",
      "0.9149\n",
      "0.9136\n",
      "0.9148\n",
      "0.9172\n",
      "0.9173\n",
      "0.9199\n",
      "0.9197\n",
      "0.9203\n",
      "0.9196\n",
      "0.9159\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images[0].shape)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.test.images.shape)\n",
    "\n",
    "#placeholder - 외부주입변수\n",
    "#변수 선언(공간확보만 한다.)\n",
    "x = tf.placeholder(tf.float32, [None,784]) #784 - flatten된것(28*28의 픽셀수)\n",
    "#바이어스 가중치 출력차수와 같음\n",
    "#10 인이유는 범주의 갯수가 10이여서(0~9)\n",
    "W = tf.Variable(tf.zeros([784,10])) #학습되는것\n",
    "b = tf.Variable(tf.zeros([10])) #학습되는것 - variable에 담긴다. - 초기화 0으로 해주었다.\n",
    "\n",
    "#얘가 model이 된다. (데이터와 가중치를 곱하는것 +바이어스)\n",
    "y = tf.nn.softmax(tf.matmul(x,W)+b) #예측값을 가지고 있다. 가중치와 곱해지고 바이어스와 더해지는 사건이 벌어지고 있다.\n",
    "#activation - softmax사용중 (다중분류기)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #실제target값\n",
    "\n",
    "#복잡도로 costfunction을 쓰고있다.\n",
    "#-가 붙은 이유 : log값의 역수가 확률이 작을 때는 높고 확률이 높을때는 작게 표현하기 위해서\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "#오차에 대하서 학습률을 적용하고, 미분을 구해서 방향을 결정하고 가중에 가감하여 가중치를 학습시킨다.\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) #cost function을 최소화하는 걸로 학습\n",
    "shape = mnist.train.images.data.shape\n",
    "sess = tf.InteractiveSession() #대화형으로 세션을 실행할 수 있도록 하는 명령\n",
    "tf.global_variables_initializer().run()\n",
    "for _ in range(1000):\n",
    "    #횟수 반복문\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100) #x,y값 100개를 돌려줌\n",
    "    sess.run(train_step, feed_dict={x:batch_xs, y_:batch_ys}) #위의 선언만 된 변수에 100개의 값들을 넣어준다.\n",
    "    #key : data 형태로 데이터를 넣어주어야한다.\n",
    "    #traing step호출 ->cross 엔트로피 -> y_, y -> x,W,b 순으로 호출된다. (그래프 자료구조로 연결되어있다.)\n",
    "    #말단의 놈만 호출하면 모든것의 계산이 실행된다.\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1)) #가장큰 확률값의 범주로 채택(인덱스로 리턴)\n",
    "    #가장큰놈의 범주의 인덱스가 같은지 비교하여 1과 0의 값을 리턴한다.(100개)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #소수점 계산을 위해 타입변환\n",
    "    print(sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
